# **5.以不变应万变：前端-视觉里程计之特征点**

愚昧从来没有给人带来幸福；幸福的根源在于知识。——左拉

---

> **本章主要内容** \
> 1.局部特征 \
> 2.特征点的分类 \
> 3. 常见的特征提取算法 \
> 4. 常见的关键点检测算法


视觉里程计对应于VSLAM中的前端部分，特征追踪是视觉里程计中的一个基础和关键的任务，它可以从两张或者多张图片中识别对应相同或相似的内容。通过追踪图像中局部特征在前后帧图像中的位置，就可以进行视觉运动估计了。特征的抽取及匹配是整个VSLAM系统中最耗时的计算过程之一，快速且鲁棒的特征点检测匹配算法可以大幅提高VSLAM算法的精度。

<a name="RlGXA"></a>
## 5.1 局部特征
图像的局部特征是一种用于描述图像中具有独特性、稳定性和可区分性的局部结构或纹理信息的方法，它可以有效地提高图像匹配的效果和精度。理想的局部特征就是一个点，在实际中，数字图像离散化时，最小单位是像素点，如果要定位某个像素点的话，必须分析该像素的邻域，所以任何局部特征都是隐式的包括一个空间范围。好的局部特征在图像的变换(如旋转、缩放、平移)下相对稳定，不会因为图像的变化而发生失效。由于全局特征容易受到噪声干扰，而局部特征比较稳定，常用于图像匹配。<br />举一个例子：想象一下我们做拼图游戏，需要把以下六个方块图案拼到下方图像对应位置，哪几个方块是最有把握的呢？<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1697277299509-b9ba76ca-d430-4c40-a3e2-914f5ac55de4.png#averageHue=%237393b4&clientId=u7d8e55e0-8eee-4&from=paste&height=287&id=ucf2645bd&originHeight=407&originWidth=554&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=903863&status=done&style=none&taskId=u97e19756-87a0-42b8-b24c-2a2e0490dc1&title=&width=390.20001220703125)<br />对于A和B,我们主要能看到的是大块的色块，其特征表现出一个面的结构，蓝色的天空都可以匹配上A，沿任何方向移动都可以，不存在唯一匹配的结果，对于B也是如此。这类结构作为特征来说是缺乏足够的区分度的。对于C和D，其中的线特征最为突出，在图中我们可以去找这些所有的线，但是我们也发现，沿着线的方向，其纹理也基本是一致的，我们可以找出线的约束方向，但却不好确定是在这个方向的哪个位置。最后来到EF,我们主要能看到一个角结构，相信大家很快就能找到其在图像中对应的位置，其中的角把两个方向都约束住了。而一定程度上角点可以代表这个角结构的位置。通过这个例子，我们可以发现点特征（如角点），相比于其他类型特征更具有区分度。后面我们也会讲到，点特征相比于线特征与面特征，对于视角变化及光照变化，具有更高的鲁棒性。

<a name="Ad3R8"></a>
## 5.2 特征点的分类
常见的特征点分为角点与斑点两类，角点检测的算法主要是定位在图像中直线交叉或者曲率变化较大的像素点，传统的方法有基于梯度和基于密度等多种方法来找角点。相比与角点检测受噪声的影响较大的缺点，斑点检测的方法更容易获得鲁棒性和稳定性的特征，因为斑点更多的是代表一个封闭的区域/圆形区域。常见的角点检测算法如Harris、Shi-Tomasi，常见的斑点检测算法如SIFT、SURF。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1697277378446-0f4d4fe8-4cd3-4ee4-bc85-ff6fa4d1b786.png#averageHue=%23ededed&clientId=u7d8e55e0-8eee-4&from=paste&height=186&id=u0e419680&originHeight=233&originWidth=660&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=616427&status=done&style=none&taskId=u47ea4a13-c5fd-4f62-b204-2ef3cb8e50e&title=&width=528)<br />图 5.2 角点与斑点<br />基于特征的图像匹配流程主要分为三个部分，特征检测、特征描述和描述子匹配。一般特征点算法流程是先进行特征检测获取特征点在图像的位置，而后对特征点的邻域进行分析提取特征描述子。而在特征追踪时会比对不同图片上的特征描述子来获取描述子的匹配对。前两个步骤统称为特征点算法，也称特征提取。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1697277481936-a54df60e-6516-4bda-aa77-378aca2d40d4.png#averageHue=%23f7f7f6&clientId=u7d8e55e0-8eee-4&from=paste&height=186&id=u341da3b2&originHeight=232&originWidth=660&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=613774&status=done&style=none&taskId=u7ed652a6-a36e-43a5-9b70-db6711d2d58&title=&width=528)<br />图 5.3 图像特征匹配流程<br />特征描述也称特征的描述子计算，通常是将特征点周边的区域的一些信息转变为一个易于识别的形式，经常表示为一个高维的向量以此来比较两个特征点是不是相似。特征描述一般有两种方法，基于梯度的方法和基于强度的方法。基于梯度的方法常见的是根据区域内的像素梯度方向来生成描述子，基于强度的方法是通过比对特定位置像素点的强弱来生成描述子，例如LBP算法通过对比邻域和中心的点的强度来生成描述子。常见的基于梯度的方法有SIFT和SURF等，基于强度的方法有LBP和BRIEF等。<br />需要注意的是，有的角点检测算法如Harris、FAST与Shi-Tomasi只有第一步特征检测，没有特征描述部分，这类算法一般称为角点检测算法，还不属于完整的特征点算法。接下来我们先介绍常用的完整的特征点算法，然后再介绍常用的角点检测算法。
<a name="eZYao"></a>
## **5.3 常见的特征提取算法**
<a name="JsJGp"></a>
### 5.3.1 SIFT
SIFT，全称为尺度不变特征变换（Scale-Invariant Feature Transform），是一种经典的特征点检测算法，该方法由加拿大教授大卫.劳伊（David G.Lowe）提取，他总结了基于不变量技术的特征检测方法，并1999年正式提出了一种基于尺度空间的、对图像缩放、旋转甚至仿射变换保持不变性的图像局部特征描述算子，这种算法在2004年被加以完善申请了专利，其专利属于英属哥伦比亚大学。SIFT专利在2020年3月17日之后到期，现在只需更新cv版本即可免费使用。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1682952698032-eafa47ba-052c-48bc-a37c-d990f2e0a0fa.png#averageHue=%239ba2a3&clientId=u536d1d11-a6b9-4&from=paste&height=246&id=uaf62eb2d&originHeight=307&originWidth=458&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=167803&status=done&style=none&taskId=udf8e65dc-eb27-4965-bd92-1a516429083&title=&width=366.4)<br />SIFT算法不仅具有尺度不变性，且在光照变化，图像旋转，视角变化中均有较好的不变性。要说缺点，就是SIFT运算复杂度太高，很耗时。<br />SIFT算法的实质可以归为在不同尺度空间上查找特征，点（关键点）的问题。其包括特征点检测，特征点描述子计算及特征点匹配算法三块。为了使主题更集中，这里主要介绍特征点检测及描述子计算两部分。匹配算法主要是计算描述子之间的距离，就不再单独介绍了。<br />首先要知道，SIFT的本质是在不同尺度空间上寻找极值点。这里的尺度空间，模拟的是人眼镜观测事物的一个特点，即近大远小。近处的物体看起来大且清晰，远处的物体，看起来小且模糊。要把事物这种与观测位置有关的成像特点表达出来，常使用高斯图像金字塔来实现。<br />先来一个简述，看看SIFT干了哪些事情，它首先从搭建图像金字塔开始，计算高斯差分图像金字塔。然后在同层及相邻层之间计算初始极值点。再使用泰勒展开计算精确极值点，其中会使用一些方法过滤掉低反应度的点及边缘点。最后使用特征点附近的梯度直方图计算主方向，并利用4x4个小方格中的8个主方向，形成128维的描述子。<br />下面就详细介绍这几个步骤：<br />**1.构建高斯差分金字塔**<br />图像的尺度空间函数，定义为原始图像I(x,y)与一个可变尺度的2维高斯函数G(x,y,σ)做卷积运算：<br />$\begin{array}{c}
L(x, y, \sigma)=G(x, y, \sigma) * I(x, y) \\
G\left(x_{i}, y_{i}, \sigma\right)=\frac{1}{2 \pi \sigma^{2}} \exp \left(-\frac{\left(x-x_{i}\right)^{2}+\left(y-y_{i}\right)^{2}}{2 \sigma^{2}}\right)
\end{array}$<br />其中σ大小决定图像的平滑程度，大尺度对应图像的概貌特征，小尺度对应图像的细节特征。大的σ值对应粗糙尺度(低分辨率)，反之，对应精细尺度(高分辨率)。<br />**1.1构建高斯图像金字塔：**<br />构建金字塔的过程主要分为两步，降采样与高斯模糊，其中高斯模糊利用高斯核来进行卷积运算，这里提一点，高斯核是线性空间中唯一可以产生多尺度空间的核。<br />降采样：下一组（octave）图像的长宽，为上一组图像长宽的一半，实现方式为行列间隔一行采样。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1682956374718-713e4ac9-eefd-4e3a-9a7e-8fd62380495d.png#averageHue=%23e8e8e8&clientId=u536d1d11-a6b9-4&from=paste&height=198&id=u3f516226&originHeight=247&originWidth=315&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=40847&status=done&style=none&taskId=u39e93f41-fcb9-44bb-9028-1b3008c96d1&title=&width=252)<br />高斯卷积：<br />根据3σ原则，使用NxN的模板在图像每一个像素点处操作，其中N=[（6σ+1）]且向上取最邻近奇数。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1682956511298-06555c4e-8002-46de-b193-2770258623c8.png#averageHue=%23e4e3e0&clientId=u536d1d11-a6b9-4&from=paste&height=355&id=u92435a0b&originHeight=623&originWidth=918&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=286862&status=done&style=none&taskId=u1a5a770d-a998-42fd-a8c7-25fed037d74&title=&width=522.4000244140625)<br />上面这样直接与图像卷积，速度比较慢，同时图像边缘信息也会损失严重。后来不知哪位学者发现，可以使用分离的高斯卷积（即先用1xN的模板沿着X方向对图像卷积一次，然后用Nx1的模板沿着Y方向对图像再卷积一次，其中N=[（6σ+1）]且向上取最邻近奇数），这样既省时也减小了直接卷积对图像边缘信息的严重损失。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1682956554444-0d26fbb7-c994-42de-9318-4f5c861cecfc.png#averageHue=%23f3f1f1&clientId=u536d1d11-a6b9-4&from=paste&height=349&id=uac89e764&originHeight=679&originWidth=1110&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=217933&status=done&style=none&taskId=ubcfd5d9c-f347-4300-b568-67113fee3a8&title=&width=570)<br />这样，在不同尺寸，不同模糊程度上，对原图像进行处理，就形成了一系列的尺度空间，如下图所示。<br />![](https://cdn.nlark.com/yuque/0/2023/gif/1782698/1682954160273-44afce41-6c7c-4bc2-bf29-45c5bee20e12.gif#averageHue=%23585858&clientId=u536d1d11-a6b9-4&from=paste&height=424&id=uf35752ef&originHeight=480&originWidth=512&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ue85bfbad-db1e-46ae-b29c-83af23b352a&title=&width=452)<br />**1.2高斯差分尺度空间**<br />为了检测到稳定的关键点，SIFT使用了高斯差分尺度空间（DOG scale-space）。利用不同尺度的高斯差分核与图像卷积生成。<br />$\begin{aligned}
D(x, y, \sigma) & =(G(x, y, k \sigma)-G(x, y, \sigma)) * I(x, y) \\
& =L(x, y, k \sigma)-L(x, y, \sigma)
\end{aligned}$<br />·高斯差分尺度空间的构建，由同组尺度图像，相邻层相减得到。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1682956153046-9f4e31b2-3d43-4989-82f5-30308518f8d2.png#averageHue=%23878880&clientId=u536d1d11-a6b9-4&from=paste&height=272&id=S6htY&originHeight=340&originWidth=525&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=216586&status=done&style=none&taskId=u3b1ca221-04d0-43dd-87bf-0caa94fadc3&title=&width=420)

**2.极值点检测**<br />在高斯差分层同组一层的每个像素点，及上下相邻层共26个点中，寻找极值点。判断条件为均大于周围点或者均小于周围点。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1682956893464-6e35fa7a-2984-4315-946f-a22a6d6865ec.png#averageHue=%23f1f1f1&clientId=u536d1d11-a6b9-4&from=paste&height=226&id=u6f0da5ed&originHeight=283&originWidth=341&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=79030&status=done&style=none&taskId=u4096ba85-9654-4d44-8a56-09c2b76feae&title=&width=272.8)<br />以上方法判断的极值点是离散空间的极值点，但离散空间的极值点并不是真正的极值点，需要通过插值的方式找到准确的极值点。利用已知的离散空间点插值得到的连续空间极值点的方法叫做子像素插值。以下通过拟合三维二次函数来精确确定关键点的位置和尺度，同时去除低对比度的关键点和不稳定的边缘响应点(因为DoG算子会产生较强的边缘响应)，以增强匹配稳定性、提高抗噪声能力。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1682957278962-150a78be-4094-43be-afe3-e9f3ade1613f.png#averageHue=%23f6f6f6&clientId=u536d1d11-a6b9-4&from=paste&height=209&id=u24ca855b&originHeight=261&originWidth=598&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=53314&status=done&style=none&taskId=u2c7b3320-5643-45b3-8a1a-179cd63bbd4&title=&width=478.4)<br />在检测到的极值点处，作三元二阶泰勒展开，计算过程如下：<br />$\begin{aligned} & f\left(\left[\begin{array}{l} x \\ y \\ \sigma \end{array}\right]\right)=f\left(\left[\begin{array}{l} x_0 \\ y_0 \\ \sigma_0 \end{array}\right]\right)+\left[\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial \sigma}\right]\left(\left[\begin{array}{l} x \\ y \\ \sigma \end{array}\right]-\left[\begin{array}{l} x_0 \\ y_0 \\ \sigma_0 \end{array}\right]\right) \\ & +\frac{1}{2}\left(\left[\begin{array}{l} x \\ y \\ \sigma \end{array}\right]-\left[\begin{array}{l} x_0 \\ y_0 \\ \sigma_0 \end{array}\right]\right)^{\mathrm{T}}\left[\begin{array}{l} \frac{\partial^2 f}{\partial x \partial x}, \frac{\partial^2 f}{\partial x \partial y}, \frac{\partial^2 f}{\partial x \partial \sigma} \\ \frac{\partial^2 f}{\partial x \partial y}, \frac{\partial^2 f}{\partial y \partial y}, \frac{\partial^2 f}{\partial y \partial \sigma} \\ \frac{\partial^2 f}{\partial x \partial \sigma}, \frac{\partial^2 f}{\partial y \partial \sigma}, \frac{\partial^2 f}{\partial \sigma \partial \sigma} \end{array}\right]\left(\left[\begin{array}{l} x \\ y \\ \sigma \end{array}\right]-\left[\begin{array}{l} x_0 \\ y_0 \\ \sigma_0 \end{array}\right]\right) \\ & \end{aligned}$<br />$H(X,Y)=\left[\begin{array}{c} \frac{\partial^2 f}{\partial x \partial x}, \frac{\partial^2 f}{\partial x \partial y} \\ \frac{\partial^2 f}{\partial x \partial y}, \frac{\partial^2 f}{\partial y \partial y} \end{array}\right]$<br />矢量形式：$f(X)=f\left(x_0\right)+\frac{\partial f^{\mathrm{T}}}{\partial X} \hat{X}+\frac{1}{2} \hat{X}^{\mathrm{T}} \frac{\partial^2 f}{\partial X^2} \hat{X}$<br />$f(X)$对X进行求导：<br />$\frac{\partial f(X)}{\partial X}=\frac{\partial f^{\mathrm{T}}}{\partial X}+\frac{1}{2}\left(\frac{\partial^2 f}{\partial X^2}+\frac{\partial f^{\mathrm{T}}}{\partial X^2}\right) \hat{X}=\frac{\partial f^{\mathrm{T}}}{\partial X}+\frac{\partial^2 f}{\partial X^2} \hat{X}$<br />令导数为0，可解得：<br />$\hat{X}=-\frac{\partial^2 f^{-1}}{\partial X^2} \frac{\partial f}{\partial X}$<br />舍去低对比度的点，若$|f(X)|<\frac{\mathrm{T}}{n}$，则舍去点$X$。<br />去除边缘效应：**本质上要去掉DoG局部曲率非常不对称的像素**，一个定义不好的高斯差分算子的极值在横跨边缘的地方有较大的主曲率，而在垂直边缘的方向有较小的主曲率。主曲率通过一个2*2的海森矩阵（Hessian Matrix）$H$求出，$D$的主曲率和$H$的特征值成正比，令$\alpha$为较大特征值，$\beta$为较小的特征值。<br />$H(x, y)=\left[\begin{array}{ll} D_{x x}(x, y) & D_{x y}(x, y) \\ D_{x y}(x, y) & D_{y y}(x, y) \end{array}\right]$<br />$\begin{aligned} & \operatorname{Tr}(H)=\alpha+\beta \quad \text { 其中: } \alpha>\beta \text { 且 } \alpha=\gamma \beta \\ & \operatorname{Det}(H)=\alpha \beta \end{aligned}$<br />若$\operatorname{Det}(H)<0$舍去$X$<br />$\frac{\operatorname{Tr}(H)}{\operatorname{Det}(H)}=\frac{(\alpha+\beta)}{\alpha \beta}=\frac{(\gamma \beta+\beta)}{\gamma \beta^2}=\frac{(\gamma+1)^2}{\gamma}$<br />若不满足$\frac{\operatorname{Tr}(H)}{\operatorname{Det}(H)}=\frac{(\gamma+1)^2}{\gamma}<\frac{(10.0+1)^2}{10.0}=1.21$舍去$X$ （建议$\gamma$取10.0）


**3.确定特征点主方向**<br />统计以特征点为圆心，以该特征点所在的高斯图像的尺度的1.5倍为半径的圆内的所有的像素的梯度方向及其梯度幅值，并做1.5σ的高斯滤波(高斯加权，离圆心也就是关键点近的幅值所占权重较高)。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1682957423981-872663df-39dd-478e-b530-2a1686453914.png#averageHue=%23bbeab7&clientId=u536d1d11-a6b9-4&from=paste&height=196&id=u6ad56c81&originHeight=245&originWidth=577&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=127985&status=done&style=none&taskId=ud8cb3ea3-692e-476d-a101-890300c2d6e&title=&width=461.6)

注：在最接近关键点尺度σ的高斯图像上进行统计.<br />关键点的方向以主方向准.<br />当关键点有两个方向，一个主方向，一个辅方向(梯度幅值>=80%主方向梯度幅值)，那么把这个关键点看成两个关键点，只不过这两个关键点的坐标和σ一样，只是方向不一样.此时关键点的方向还是离散的，我们需要进行抛物线插值。

**4.计算描述子**<br />上述过程，只是找到关键点并确定了其方向，但SIFT算法核心用途在于图像的匹配，我们需要对关键点进行数学层面的特征描述，也就是构建关键点描述符.<br />**1. 确定计算描述子所需的图像区域**<br />描述子梯度方向直方图由关键点所在尺度的高斯图像计算产生. 图像区域的半径通过下式(17)计算<br />$\text { radius }=\frac{3 \sigma \sqrt{2}(d+1)+1}{2}$<br />其中$d=4$<br />注：$d=4$，代表划分4*4个子块。<br />**2. 将坐标移至关键点方向**<br />关键点所在的半径区域，移至关键点方向，如图6所示：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1682957511159-fba32612-1980-42f3-8fc3-ea65ea1fba7d.png#averageHue=%23eff3e7&clientId=u536d1d11-a6b9-4&from=paste&height=200&id=ua86a9bbb&originHeight=250&originWidth=506&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=107962&status=done&style=none&taskId=u8f85745f-533a-4057-a1ad-cd1186c893a&title=&width=404.8)<br />**3. 生成关键点描述符**<br />如图7所示：将区域划分为4×4的子块，对每一子块进行8个方向的直方图统计操作，获得每个方向的梯度幅值，总共可以组成128维描述向量。

![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1682957532050-2af29452-9fad-4ddc-9289-5e1045fb165c.png#averageHue=%23ddf4d5&clientId=u536d1d11-a6b9-4&from=paste&height=400&id=u21b3b372&originHeight=500&originWidth=700&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=302590&status=done&style=none&taskId=u30feaedd-ec2c-4950-aa22-980cb7bc8a0&title=&width=560)

SIFT算法首先在图像中检测出关键点，然后计算每个关键点周围的局部特征描述子。关键点的选择基于图像的极值点，同时考虑尺度空间和高斯差分图像。关键点的描述子由关键点周围的梯度方向直方图构成，该直方图具有旋转不变性和尺度不变性。<br />其中，第一步是构建高斯金字塔，将原始图像不断缩小，得到不同尺度的图像。第二步是构建高斯差分金字塔，从高斯金字塔中相邻两层图像相减，得到不同尺度的差分图像。第三步是在高斯差分金字塔中检测极值点，即在每个尺度的差分图像中寻找局部极值点。第四步是对极值点进行精确定位和尺度估计。第五步是确定特征方向，计算关键点周围像素点的梯度方向直方图，然后选择主方向作为关键点的描述子。最后，将关键点的描述子归一化，得到具有旋转不变性和尺度不变性的特征描述子。<br />总体而言，SIFT算法是一种非常有效的图像特征提取算法，能够有效地用于图像匹配、目标识别等领域。
<a name="sHdX2"></a>
### 5.3.2 SURF
SIFT有着较好的效果，但是计算很耗时，这个特征计算也很复杂，大家就想怎么去改进它，因为它在找特征点时，一个卷积操作是比较耗时的，第二个就是在找到极值点后，还需要计算一个海森矩阵来去除边缘点，这一步也是比较耗时的，所以有学者就在想怎么去优化这几步。于是SURF诞生了。<br />SURF全称为Speeded Up Robust Features，由Herbert Bay等人在2006年提出。SURF算法主要分为三个步骤：尺度空间极值检测、关键点定位和方向分配。在尺度空间极值检测中，SURF使用了Hessian矩阵来检测图像中的稳定特征点。在关键点定位中，SURF使用了一种叫做“盒子滤波器”的算法来定位关键点。在方向分配中，	SURF使用了一个类似于SIFT的方法来确定每个关键点的主方向。<br />与SIFT相比，SURF具有更快的计算速度和更好的尺度不变性。<br />**1.极值检测**<br />SURF检测极值点的方式是利用海森矩阵，该海森矩阵是原图像经过高斯核处理后的多尺度图像。在尺度σ下，点x=(x,y)处的Hessian值为：<br />$H(\boldsymbol{x}, \sigma)=\left[\begin{array}{ll}
L_{x x}(\boldsymbol{x}, \sigma) & L_{x y}(\boldsymbol{x}, \sigma) \\
L_{y x}(\boldsymbol{x}, \sigma) & L_{y y}(\boldsymbol{x}, \sigma)
\end{array}\right]$<br />其中Lxx(x,σ)是二维高斯核与图像做卷积后的二阶微分，但这个卷积很耗时，SURF的思想就是，用常值代替微分值，然后使用积分图加速卷积过程。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683038804204-5574ba92-fce2-41fd-b282-fae11e88638b.png#averageHue=%23e3e2e2&clientId=u8bf38a8a-db5a-4&from=paste&height=222&id=u04f27ce3&originHeight=277&originWidth=829&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=36478&status=done&style=none&taskId=u5a20d3ea-ff60-40c1-8570-726bb3ce208&title=&width=663.2)<br />从左到右：在y方向和xy方向上的（离散和裁剪的）高斯二阶偏导数，以及我们使用盒滤波器对其的近似。灰色区域等于零。<br />右边尺度的核，是左边高斯核的近似，称为盒式滤波器。而配合盒式滤波器使用的，是积分图。<br />积分图主要的思想是将图像从起点开始到各个点所形成的矩形区域像素之和作为一个数组的元素保存在内存中，当要计算某个区域的像素和时可以直接索引数组的元素，不用重新计算这个区域的像素和，从而加快了计算。<br />求取积分图时，对图像所有像素遍历一遍，得到积分图后，计算任何矩形区域内的像素灰度和只需进行三次加减运算，如下图所示。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683038946346-c39b8353-bc01-4482-8dd7-5aa878e1325d.png#averageHue=%23eeebdf&clientId=u8bf38a8a-db5a-4&from=paste&id=ub8e3d2eb&originHeight=286&originWidth=1816&originalType=url&ratio=1.25&rotation=0&showTitle=false&size=42030&status=done&style=none&taskId=u49a88064-a6d9-447b-b6a1-70f79d380b3&title=)<br />图中绿色区域的面积为：A-B-C+D，因为在减法的过程中，多减了一次D，所以最后要加上一个D。<br />因为不是用的真正的高斯核，所以最后海森矩阵的值不太准确，为了和真实高斯核值接近，这里使用了如下方式计算海森矩阵行列式<br />每个像素的Hessian矩阵行列式的近似值：<br />$\operatorname{det}(H)=D_{x x} * D_{y y}-w * D_{x y}^{2}$<br />滤波器响应的相关权重$w$是为了平衡Hessian行列式的表示式。这是为了保持高斯核与近似高斯核的一致性。<br />$w=\frac{\left|L_{x y}(\sigma)\right|_F\left|D_{x x}(\sigma)\right|_F}{\left|L_{x x}(\sigma)\right|_F\left|D_{x y}(\sigma)\right|_F}=0.912$<br />其中$|X|_F$为Frobenius范数。理论上来说对于不同的$\sigma$的值和对应尺寸的模板尺寸，$w$值是不同的，但为了简化起见，可以认为它是同一个常数0.9。在实际计算滤波响应值时，需要使用模板中盒式区域的面积进行归一化处理，以保证一个统一的Frobenius范数能适应所有的滤波尺寸。<br />这样就得到了每个像素的“斑点（blob)”响应值，且这个值是过滤掉了边缘点的。不需要在定位后再去除一遍。<br />接下来需要构建尺度空间了，与sift的既有降采样，又有高斯模糊不同，Surf没有降采样。在Surf中，不同组间图像的尺寸都是一致的，但不同组间使用的盒式滤波器的模板尺寸逐渐增大(核长宽越来越大)，同一组间不同层间使用相同尺寸的滤波器，但是滤波器的模糊系数逐渐增大（模糊系数是啥）。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683039596515-41523485-73b4-44fd-b59a-24fbb4765717.png#averageHue=%23e9e9e9&clientId=u8bf38a8a-db5a-4&from=paste&height=173&id=u47335664&originHeight=216&originWidth=531&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=53210&status=done&style=none&taskId=ud7218f27-67cb-44af-9129-fe40d02f8cc&title=&width=424.8)<br />在sift中，通过不断地减小图像尺寸来模拟远近变化，而SURF是通过改变fiter的尺寸来实现不同尺度的获得，不会因为filter尺寸的变大而使得计算量变大，因为在卷积是仅仅是查找积分图中的四个角处的数值，所有层的计算代价都是相同的。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683039633415-316779de-fa36-442f-902e-8f4c48709c80.png#averageHue=%23fafafa&clientId=u8bf38a8a-db5a-4&from=paste&height=257&id=u60791e90&originHeight=321&originWidth=676&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=73243&status=done&style=none&taskId=u358cc245-273b-480a-a02c-144121a5f1e&title=&width=540.8)<br />SURF的尺度空间中不同层所用的filter size如上图所示。<br />特征点的定位过程Surf和Sift保持一致，将经过Hessian矩阵处理的每个像素点与二维图像空间和尺度空间邻域内的26个点进行比较，初步定位出关键点，再经过滤除能量比较弱的关键点以及错误定位的关键点，筛选出最终的稳定的特征点。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683039780584-352d6b95-d136-45db-9c00-43be1d8e6a4c.png#averageHue=%23ededed&clientId=u8bf38a8a-db5a-4&from=paste&height=447&id=u7b0331da&originHeight=559&originWidth=655&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=197443&status=done&style=none&taskId=ud38aabaf-1203-4af4-ba1b-bea5bd6430d&title=&width=524)<br />同sift相同，取得极值位置后，还需要对极值进行二次精确定位，具体方法和sift中相同。

**2.方向计算**<br />Sift特征点方向分配是采用在特征点邻域内统计其梯度直方图，而在Surf中，采用的是统计特征点圆形邻域内的haar小波特征。小波特征也可以看做是和盒式滤波器相同的核。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683039974180-0fa7f420-dde1-4a18-9413-05346d8bf42b.png#averageHue=%23afafaf&clientId=u8bf38a8a-db5a-4&from=paste&height=156&id=u39fdf3dc&originHeight=195&originWidth=386&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=5386&status=done&style=none&taskId=u7b81a78a-77f0-4735-b5f4-762c3431140&title=&width=308.8)<br />在特征点的圆形邻域内，统计60度扇形内所有点的水平、垂直haar小波特征总和，然后扇形以一定间隔进行旋转并再次统计该区域内haar小波特征值之后，最后将值最大的那个扇形的方向作为该特征点的主方向。<br />**统计60度扇形内所有点的水平、垂直haar小波特征总和**<br />其具体方法是首先在特征点位置画一个直径为6s的圆形，s为尺度。分别计算这个圆中的每个以s*s为间隔取样的点处的haarX和haarY特征，同时计算每个点的特征方向  ：<br />$\theta _{i} = arctan(\frac{harrY}{haarX})$<br />在一个60度的扇形中统计落在扇形角度范围内的点的harrX和HarrY各自之和sumX和sumY，该扇形以每次15度的精度绕中心旋转，选取使得sum的模长最大的扇形方向为该特征点的方向，其中，harr小波特征的计算需要再次用到积分图。<br />使用$\sigma=2s$的高斯函数对Haar小波的响应值进行加权。为了求主方向，设计一个以特征点为中心，张角为$\pi/3$的扇形窗口，以一定旋转角度$\theta$旋转窗口，并对窗口内的Haar小波响应值$dx$ , $dy$进行累加，得到一个矢量(mw, θw) :<br />$m_w = \sum_{w} dx+\sum_{w} dy$<br />$\theta=arctan(\sum_{w} dy/\sum_{w} dx)$<br />主方向为最大Haar响应累加值所对应的方向，即$\theta=\theta_w|max \{ m_w\}$，当存在大于主峰值80%以上的峰值时，则将对应方向认为是该特征点的辅方向。一个特征点可能会被指定多个方向，可以增强匹配的鲁棒性。其过程示意图如下:<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683040500602-c76c4e24-75ab-42d3-804d-3d0e686404d2.png#averageHue=%23f9f8f8&clientId=u8bf38a8a-db5a-4&from=paste&height=294&id=u97d17f53&originHeight=368&originWidth=1066&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=171305&status=done&style=none&taskId=u78774ce9-1bd8-44cd-805a-39b4672087f&title=&width=852.8)<br />如图所示，求取主方向时扇形滑动窗口围绕特征点转动，统计Haar小波响应值，并计算方向角。<br />**3.描述子计算**<br />在Sift中，是取特征点周围4*4个区域块，统计每小块内8个梯度方向，用着4*4*8=128维向量作为Sift特征的描述子。<br />Surf算法中，也是在特征点周围取一个4*4的矩形区域块，但是所取得矩形区域方向是沿着特征点的主方向。每个子区域统计25个像素的水平方向和垂直方向的haar小波特征，这里的水平和垂直方向都是相对主方向而言的。该haar小波特征为水平方向值之后、垂直方向值之后、水平方向绝对值之后以及垂直方向绝对值之和4个方向。该过程示意图如下：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683040555937-31b5a595-8984-4dcb-9c80-743c63c867c2.png#averageHue=%23e4e3b8&clientId=u8bf38a8a-db5a-4&from=paste&height=378&id=u8185fad3&originHeight=472&originWidth=890&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=247661&status=done&style=none&taskId=u8ca0a9c6-f70e-476c-8906-2181d206c9a&title=&width=712)<br />把这4个值作为每个子块区域的特征向量，所以一共有4*4*4=64维向量作为Surf特征的描述子，比Sift特征的描述子减少了2倍。<br />SURF描述子不仅具有尺度和旋转不变性，还具有光照不变性，这由小波响应本身决定，而对比度不变性则是通过将特征向量归一化来实现。从下图为3种简单模式图像及其对应的特征描述子可以看出，引入Haar小波响应绝对值的统计和是必要的，否则只计算 :<br />$\sum dx,\sum dy$的话，第一幅图和第二幅图的特征表现形式是一样的，因此，采用4个统计量描述子区域使特征更具有区分度。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683040725886-ef3613a4-c351-4547-9c8d-4ea3259cbfa3.png#averageHue=%23c3c2c2&clientId=u8bf38a8a-db5a-4&from=paste&height=178&id=u7169f765&originHeight=223&originWidth=541&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=27109&status=done&style=none&taskId=u08dfc127-b933-4dd4-9483-8b8562a6f7b&title=&width=432.8)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683040752878-556ff7d6-0cce-4220-a003-35e36ee50e82.png#averageHue=%23eeeae6&clientId=u8bf38a8a-db5a-4&from=paste&height=194&id=u35b9f477&originHeight=243&originWidth=784&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=46122&status=done&style=none&taskId=u085fe3b4-f5b0-49db-a724-f31dc1b4a0d&title=&width=627.2)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683040767170-a3a9f99a-ab71-49a7-8452-16e1c4ee647d.png#averageHue=%23e2dfdf&clientId=u8bf38a8a-db5a-4&from=paste&height=251&id=ue7ee98b7&originHeight=314&originWidth=511&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=54554&status=done&style=none&taskId=ue1197398-e276-42a9-80c9-d538b6884e4&title=&width=408.8)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683040779500-de587c8e-5165-4795-9485-f1ae41130dda.png#averageHue=%23f2f0ee&clientId=u8bf38a8a-db5a-4&from=paste&height=122&id=ub6553b91&originHeight=152&originWidth=809&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=25708&status=done&style=none&taskId=ua7a16add-d856-4b9c-a8ce-f037f6b209c&title=&width=647.2)
<a name="DPjKU"></a>
### 5.3.3 KAZE
KAZE 算法（KAZE 是日语 "风" 的意思）是一种用于特征检测和描述的计算机视觉算法。与 SIFT 和 SURF 算法类似，KAZE 也构建了尺度空间（scale-space）来在不同尺度的图像中检测关键点。KAZE 与其他算法的主要区别在于它使用了非线性尺度空间（non-linear scale-space）。<br />KAZE 构建尺度空间的步骤如下：

1.  **构建非线性尺度空间**：KAZE 使用一种叫做 "非线性扩散滤波"（non-linear diffusion filtering）的方法来构建尺度空间。对于每个尺度层，KAZE 使用一个不同的时间参数（t）来对原始图像进行非线性扩散滤波。这里的时间参数（t）相当于其他尺度空间中的高斯滤波器的方差（σ²）。 
2.  **计算特征响应**：KAZE 使用一个叫做 "Hessian 矩阵行列式"（Determinant of Hessian matrix）的方法来计算每个像素点的特征响应。特征响应越大，表示该点越可能是一个关键点。 
3.  **关键点检测**：KAZE 使用了一个类似于 SIFT 的方法来检测关键点。对于每个尺度层，KAZE 首先找到特征响应的局部极值点（在 3x3x3 的邻域内比邻居的响应更强），然后用一个阈值对特征响应进行筛选，最后保留特征响应较大的点作为关键点。 
4.  **关键点描述**：对于每个关键点，KAZE 提取一个特征描述子。描述子是一个向量，用于表示关键点周围的图像信息。KAZE 描述子是基于梯度直方图的，与 SIFT 描述子类似，但使用了不同的方法来计算梯度。KAZE 描述子具有较好的旋转不变性和尺度不变性。 

具体步骤如下：<br />**1.使用非线性扩散滤波构建尺度空间**<br />(1) 非线性扩散滤波<br />非线性扩散滤波方法是将图像亮度（L）在不同尺度上的变化视为某种形式的流动函数的散度，可以通过非线性偏微分方程来描述：<br />$\frac{\partial L}{\partial t}=\operatorname{div}(c(x, y, t) \cdot \nabla L)$<br />其中c(x,y,t)为传导函数，可由下式来构造：<br />$c(x, y, t)=g\left(\left|\nabla L_{\sigma}(x, y, t)\right|\right)$<br />其中的▽Lσ是高斯平滑后的图像Lσ的梯度，《KAZE Features》一文中给出了g()函数的几种表达形式：<br />$\begin{aligned} & g_1=\exp \left(-\frac{\left|\nabla L_\sigma\right|^2}{k^2}\right), g_2=\frac{1}{1+\frac{\left|\nabla L_\sigma\right|^2}{k^2}} \\ & g_3=\left\{\begin{array}{cl} 1 & ,\left|\nabla L_\sigma\right|^2=0 \\ 1-\exp \left(-\frac{3.315}{\left(\left|\nabla L_\sigma\right| / k\right)^8}\right) & ,\left|\nabla L_\sigma\right|^2>0 \end{array}\right. \\ & \end{aligned}$<br />其中g1能够保留高对比度的边缘，g2能够保留宽度较大的区域，g3能够有效平滑区域内部而保留边界信息，《KAZE Features》一文中选择g2。参数k是控制扩散级别的对比度因子，决定保留多少边缘信息，其值越大，保留的边缘信息越少。<br />(2)AOS算法<br />	非线性扩散滤波中的偏微分方程没有解析解。因此，需要使用数值方法来逼近微分方程。将上述偏微分方程离散化：<br />$\frac{L^{i+1}-L^i}{\tau}=\sum_{l=1}^m A_l\left(L^i\right) L^{i+1}$<br />其中Al是表示图像在各维度（l）上传导性的矩阵，τ为时间步长。该方程的解如下：<br />$L^{i+1}=\left(I-\tau \sum_{l=1}^m A_l\left(L^i\right)\right)^{-1} L^i$

与SIFT不同的是，KAZE无需对图像进行下采样，各个层级均采用与原始图像相同的分辨率。非线性扩散滤波模型是以时间为单位的，故需要将尺度参数转换为时间（此处称为进化时间）。在高斯尺度空间下，使用标准差为σ的高斯核对图像进行卷积，相当于对图像进行持续时间为t=σσ/2的滤波，故两者的转换公式为：t=σσ/2。根据一组进化时间，利用AOS算法即可得到非线性尺度空间的所有图像：<br />$L^{i+1}=\left(I-\left(t_{i+1}-t_i\right) \sum_{i=1}^m A_i\left(L^i\right)\right)^{-1} L^i$<br />**2.多尺度空间检测极值点**<br />KAZE的特征点检测与SURF类似。是通过寻找不同尺度归一化后的Hessian行列式的局部极大值（或者极小值）点来实现的。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683080360382-88dcc274-9811-4ff5-be00-177d425315b6.png#averageHue=%23efefef&clientId=ub63f5f97-eb7f-4&from=paste&height=242&id=u70c37f33&originHeight=303&originWidth=356&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=85866&status=done&style=none&taskId=u56265f1a-a770-449f-9be8-1b1ad7d8515&title=&width=284.8)<br />如上图中画×的特征点，比较其与同一层中周围的8个像素点，再加上相邻层的9+9=18个像素点，即26个像素点，当其大于（或者小于）所有相邻点时，该点就是极值点。<br />**3.极值点精确定位**<br />这一过程和SIFT一样，通过泰勒表达式：<br />$L(\mathbf{x})=L+\left(\frac{\partial L}{\partial \mathbf{x}}\right)^T \mathbf{x}+\frac{1}{2} \mathbf{x}^T \frac{\partial^2 L}{\partial \mathbf{x}^2} \mathbf{x}$<br />对其求导数，并令导数等于零，解得<br />$\hat{\mathbf{x}}=-\left(\frac{\partial^2 L}{\partial \mathbf{x}^2}\right)^{-1} \frac{\partial L}{\partial \mathbf{x}}$<br />将解带入泰勒表达式，得：<br />$L(\hat{X})=L+\frac{1}{2}\left(\frac{\partial L}{\partial X}\right)^T \hat{X}$<br />$|L(\hat{X})| \geq T$<br />时保留该特征点，否则剔除。<br />**4.特征点主方向计算**<br />这一过程和SURF一样。若特征点的尺度参数为σi，则搜索半径设为6σi。在这个圆形领域内做一个60度的扇形区域，统计这个扇形区域内的haar小波特征总和，然后转动扇形区域，再统计小波特征总和。小波特征总和最大的方向为主方向。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683080567225-c6fb1bef-f705-4cdc-a7ea-3f2508d90c68.png#averageHue=%23f8f7f7&clientId=ub63f5f97-eb7f-4&from=paste&height=151&id=u1a9eeec6&originHeight=189&originWidth=564&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=62190&status=done&style=none&taskId=ue411e049-9268-46bb-86da-9a71e8b4b9f&title=&width=451.2)<br />**5.生成特征点描述子**<br />对于尺度参数为σi的特征点，在梯度图像上以特征点为中心取一个24σi×24σi的窗口，并将窗口划分为4×4个子区域，每个子区域大小为9σi×9σi，相邻的子区域有宽度为2σi的交叠带（此处我认为应该是相邻的子区域有宽度为4σi的交叠带，不然24σi不够划分为4×4个子区域）。每个子区域都用一个高斯核（σ1 =2.5σi）进行加权，然后计算出长度为4的子区域描述向量：<br />$d_v=\left(\sum L_x, \Sigma L_y, \Sigma\left|L_x\right|, \Sigma\left|L_y\right|\right)$<br />再通过另一个大小为4×4的高斯窗口（σ2 =1.5σi）对每个子区域的向量dv进行加权，最后进行归一化处理。这样就得到了4×4×4=64维的描述向量。<br />到此KAZE特征检测算法的原理算是讲完了，下面说一下KAZE特征的优缺点。<br />优点：<br />(1)在图像模糊、噪声干扰和压缩重构等造成的信息丢失的情况下，KAZE特征的鲁棒性明显优于其它特征。<br />(2)相比于线性尺度空间，非线性尺度空间不会造成边界模糊和细节丢失，而且更稳定。<br />缺点：<br />(1)KAZE算法在尺度不变性上是逊于SIFT的。<br />(2)KAZE特征的匹配对参数的设置比较敏感。<br />(3)KAZE特征的检测时间高于SURF，但与SIFT相近。

<a name="gDxza"></a>
### 5.3.4 ORB
简单来说，ORB = Oriented FAST（特征点） + Rotated BRIEF（特征描述）<br />FAST速度是快，但是无法体现出一个优良特征点的尺度不变性和旋转不变性。Fast角点本不具有方向，由于特征点匹配需要，ORB对Fast角点进行了改进，改进后的 FAST 被称为 Oriented FAST，具有旋转和尺度的描述。<br />**那么，Oriented FAST是怎么解决这个问题呢？**<br />从SIFT过来的我们对这个问题不陌生。

   - 尺度不变性：可以用金字塔解决；
   - 旋转不变性：可以用质心标定方向解决；

**尺度不变性：**

   1. 对图像做不同尺度的高斯模糊
   2. 对图像做降采样(隔点采样)
   3. 对每层金字塔做FAST特征点检测
   4. n幅不同比例的图像提取特征点总和作为这幅图像的oFAST特征点。

**旋转不变性：**<br />1、在一个小的图像块 B 中，定义图像块的矩。<br />$m_{p q}=\sum_{x, y} x^p y^q I(x, y)$<br />2、通过矩可以找到图像块的质心<br />$C=\left(\frac{m_{10}}{m_{00}}, \frac{m_{01}}{m_{00}}\right)$<br />3、连接图像块的几何中心 O 与质心 C，得到一个方向向量 OC→ ，这就是特征点的方向。<br />$\theta=\operatorname{atan} 2\left(m_{01}, m_{10}\right)$<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683210621520-035d7510-2b69-47dc-b055-0eaf7e803beb.png#averageHue=%23faf8f8&clientId=u84dae985-42ee-4&from=paste&height=306&id=woSnq&originHeight=382&originWidth=783&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=118455&status=done&style=none&taskId=u37474cda-5be0-4076-ac29-7da8f90f14b&title=&width=626.4)<br />**BRIEF**<br />BRIEF是2010年的一篇名为《BRIEF:Binary Robust Independent Elementary Features》的文章中提出，BRIEF是对已检测到的特征点进行描述，它是一种二进制编码的描述子，摒弃了利用区域灰度直方图描述特征点的传统方法，采用二进制、位异或运算，大大的加快了特征描述符建立的速度，同时也极大的降低了特征匹配的时间，是一种非常快速，很有潜力的算法。<br />如果说FAST用来解决寻找特征点的速度问题，那么BRIEF就用来解决描述子的空间占用冗余问题。<br />**特征点怎么来？**<br />好了，我们知道了BRIEF的实质就是特征点的描述子。那么前提就是描述对象特征点从何而来？实际上，Harris/FAST/SIFT/SURF等算法提供的特征点都可以。<br />**描述子怎么加？**<br />先定格调：在关键点周围做像素值比较，得到的结果是二进制串。<br />那下面就看一看它是如何给这些特征点加上描述子的：<br />1、为减少噪声干扰，先对图像进行高斯滤波（方差为2，高斯窗口为9x9）<br />2、以特征点为中心，取SxS的邻域窗口。在窗口内随机选取一对（两个）点，比较二者像素的大小，进行如下二进制赋值。<br />$\tau(\mathbf{p} ; \mathbf{x}, \mathbf{y}):= \begin{cases}1 & : \mathbf{p}(\mathbf{x})<\mathbf{p}(\mathbf{y}) \\ 0 & : \mathbf{p}(\mathbf{x}) \geq \mathbf{p}(\mathbf{y})\end{cases}$<br />其中，p(x)，p(y)分别是随机点x=(u1,v1),y=(u2,v2)的像素值。

3、在窗口中随机选取N对随机点，重复步骤2的二进制赋值，形成一个二进制编码，这个编码就是对特征点的描述，即特征描述子。（一般N=256）<br />这个特征可以由n位二进制测试向量表示，BRIEF描述子：<br />$f_n(\mathbf{p}):=\sum_{1 \leq i \leq n} 2^{i-1} \tau\left(\mathbf{p} ; \mathbf{x}_i, \mathbf{y}_i\right)$<br />这里面，最关键的地方其实是随机特征对的选取，论文中就给出了5种方法（其中第二种比较好)，分别为:<br />1.$x_i, y_i$都呈均匀分布$\left[-\frac{S}{2}, \frac{S}{2}\right]$；<br />2.$x_i, y_i$都呈高斯分布$\left[0, \frac{1}{25} S^2\right]$，准则采样服从各向同性的同一高斯分布;<br />3.$x_i$服从高斯分布$\left[0, \frac{1}{25} S^2\right]$，$y_i$ 服从高斯分布$\left[x_i, \frac{1}{100} S^2\right]$，采样分两步进行: 首先在原 点处为$x_i$进行高斯采样，然后在中心为$x_i$处为$y_i$ 进行高斯采样; <br />4.$x_i, y_i$在空间量化极坐标下的离散位置处进行随机采样; <br />5.$x_i=(0,0)^T$，$y_i$在空间量化极坐标下的离散位置处进行随机采样;<br />这5种方法生成的256对(OpenCVi中用32个字节存储这256对)随机点如下（一条线段的两个端点是一对）：

![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683210892351-ce5e22a2-8334-4e70-803a-ff4e0a65b934.png#averageHue=%23e2e2e2&clientId=u84dae985-42ee-4&from=paste&height=193&id=eYatQ&originHeight=241&originWidth=784&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=184974&status=done&style=none&taskId=uc1dab4bc-1b6e-40d5-847e-530c7cfdaa0&title=&width=627.2)<br />经过上面三个步骤，我们就可以为每个特征点表示为一个256bit的二进制编码。<br />Rotated BRIEF<br />在介绍ORB的改善之前，我们先思考一个问题。描述子是用来描述一个特征点的属性的，除了标记特征点之外，它最重要的一个功能就是要实现特征点匹配。BRIEF是如何实现特征点匹配的呢？<br />答案是：Hamming距离！<br />汉明距离是使用在数据传输差错控制编码里面的，汉明距离是一个概念，它表示两个（相同长度）字对应位不同的数量，我们以d（x,y）表示两个字x,y之间的汉明距离。对两个字符串进行异或运算，并统计结果为1的个数，那么这个数就是汉明距离。

   1. 两个特征编码对应bit位上相同元素的个数小于128的，一定不是配对的。
   2. 一幅图上特征点与另一幅图上特征编码对应bit位上相同元素的个数最多的特征点配成一对。

其实就是**按位求异或**的过程。（相同为0，不同为1）<br />所以，对于BRIEF来说，描述子里不包含旋转属性，所以一旦匹配图片有稍微大点的旋转角度，按照Hamming算法，匹配度将会大幅下降。

**ORB如何优化？**<br />**首先，做一些前期优化：**

   1. ORB算法进一步增强描述子的抗噪能力，采用积分图像来进行平滑；
   2. 在特征点的31x31邻域内，产生随机点对，并以随机点为中心，取5x5的子窗口。
   3. 比较两个随机点的子窗口内25个像素的大小进行编码（而不仅仅是两个随机点了）

其次，为BRIEF增加旋转不变性（Steered BRIEF）：

ORB算法采用关键点的主方向来旋转BEIEF描述子。

1、对于任意特征点，在31x31邻域内位置为(xi,yi)的n对点集，可以用2 x n的矩阵来表示：<br />$S=\left(\begin{array}{l} x_1, \cdots, x_n \\ y_1, \cdots, y_n \end{array}\right)$<br />2、利用FAST求出的特征点的主方向$\theta$和对应的旋转矩阵$R_\theta$，算出旋转的$S_\theta$来代表$S$:<br />$\begin{aligned} & \theta=\operatorname{atan} 2\left(m_{01}, m_{10}\right) \\ & R_\theta=\left[\begin{array}{cc} \cos \theta & -\sin \theta \\ \sin \theta & \cos \theta \end{array}\right] \\ & S_\theta=R_\theta S \end{aligned}$<br />3、计算旋转描述子（**steered BRIEF**）:<br />$g_n(p, \theta):=f_n(p) \mid\left(x_i, y_i\right) \in S_\theta$<br />其中$f_n(\mathbf{p}):=\sum_{1 \leq i \leq n} 2^{i-1} \tau\left(\mathbf{p} ; \mathbf{x}_i, \mathbf{y}_i\right)$为BRIEF的描述子<br />**最后，rBRIEF-改进特征点描述子的相关性**<br />使用steeredBRIEF方法得到的特征描述子具有旋转不变性，但是却在另外一个性质上不如原始的BRIEF算法。是什么性质呢，是描述符的可区分性，或者说是相关性。这个性质对特征匹配的好坏影响非常大。描述子是特征点性质的描述。描述子表达了特征点不同于其他特征点的区别。我们计算的描述子要尽量的表达特征点的独特性。如果不同特征点的描述子的可区分性比较差，匹配时不容易找到对应的匹配点，引起误匹配。ORB论文中，作者用不同的方法对100k个特征点计算二进制描述符，对这些描述符进行统计，如下表所示：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683211140788-3f708cca-c807-4e43-a92c-6f665fcd956b.png#averageHue=%23fbf7f7&clientId=u84dae985-42ee-4&from=paste&height=472&id=YsIhb&originHeight=590&originWidth=795&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=105293&status=done&style=none&taskId=u52586628-4379-4546-9b67-9728adef55c&title=&width=636)<br />我们先不看rBRIEF的分布。对BRIEF和steeredBRIEF两种算法的比较可知，BRIEF算法落在0上的特征点数较多，因此BRIEF算法计算的描述符的均值在0.5左右，每个描述符的**方差较大，可区分性较强**。而steeredBRIEF失去了这个特性。<br />至于为什么均值在0.5左右，方差较大，可区分性较强的原因，这里大概分析一下。这里的描述子是二进制串，里面的数值不是0就是1，如果二进制串的均值在0.5左右的话，那么这个串有大约相同数目的0和1，那么方差就较大了。用统计的观点来分析二进制串的区分性，如果两个二进制串的均值都比0.5大很多，那么说明这两个二进制串中都有较多的1时，在这两个串的相同位置同时出现1的概率就会很高。那么这两个特征点的描述子就有很大的相似性。这就增大了描述符之间的相关性，减小之案件的可区分性。<br />下面我们介绍解决上面这个问题的方法：**rBRIEF**。<br />原始的BRIEF算法有5种去点对的方法，原文作者使用了方法2。为了解决描述子的可区分性和相关性的问题，ORB论文中没有使用5种方法中的任意一种，而是使用统计学习的方法来重新选择点对集合。

**首先，**建立300k个特征点测试集。<br />备注：<br />	对于测试集中的每个点，预处理参考第一个步骤。考虑其31x31邻域。这里不同于原始BRIEF算法的地方是，这里在对图像进行高斯平滑之后，使用邻域中的某个点的5x5邻域灰度平均值来代替某个点对的值，进而比较点对的大小。这样特征值更加具备抗噪性。另外可以使用积分图像加快求取5x5邻域灰度平均值的速度。<br />**其次，**特征点选取<br />从上面可知，在31 x 31的邻域内共有(31-5+1)x(31-5+1)=729个这样的子窗口，那么取点对的方法共有M=205590种，我们就要在这Ｍ种方法中选取256种取法，选择的原则是这256种取法之间的相关性最小。怎么选取呢？

   - 在300k特征点的每个31x31邻域内按M种方法取点对，比较点对大小，形成一个300k x M的二进制矩阵Q。矩阵的每一列代表300k个点按某种取法得到的二进制数。
   - 对Q矩阵的每一列求取平均值，按照平均值到0.5的距离大小重新对Q矩阵的列向量排序，形成矩阵T。
   - 将T的第一列向量放到R中
   - 取T的下一列向量和R中的所有列向量计算相关性，如果相关系数小于设定的阈值，则将T中的该列向量移至R中。
   - 按照第四步的方式不断进行操作，直到R中的向量数量为256。
   - 通过这种方法就选取了这256种取点对的方法。这个算法是对均值靠近0.5的不相关测试进行贪婪搜索，结果称为rBRIEF。rBRIEF在方差和相关性上与旋转BRIEF相比有明显进步（如图4）。PCA的特征值较高，它们的下降速度要快得多。

![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683211317473-34b18f93-24b5-4ade-94ca-e39d20407e38.png#averageHue=%23fbfafa&clientId=u84dae985-42ee-4&from=paste&height=362&id=u10gZ&originHeight=453&originWidth=782&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=114176&status=done&style=none&taskId=u29696271-a597-44c0-98ed-b6bcd7dafe4&title=&width=625.6)<br />至此，ORB的优化就结束了。我们尝试总结一下：<br />FAST是用来寻**找特征点**的。ORB在FAST基础上通过金字塔、质心标定解决了尺度不变和旋转不变。即oFAST。<br />BRIEF是用来**构造描述子**的。ORB在BRIEF基础上通过引入oFAST的旋转角度和机器学习解决了旋转特性和特征点难以区分的问题。即rBRIEF.<br />现在，有了特征点寻找和描述子，ORB就成了！

<a name="XI2ln"></a>
## **5.4 常见的关键点检测算法**
<a name="JkAtz"></a>
### 5.4.1 Harris角点
Harris角点是这样的，假设在一个图像上画一个窗口，在平面中，窗口向任意一个方向移动，窗口内像素灰度不会有太大变化，如果是在一条线段上，平行于线段移动，窗口内像素灰度不会有太大变化，而垂直于线段移动则会有较大变化。如果是角点的话，朝任意方向移动，窗口内像素灰度都会有较大变化。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683206511234-8baa7991-11a7-4179-86c4-84bea2e60685.png#averageHue=%23d3d3d3&clientId=u84dae985-42ee-4&from=paste&height=466&id=u1e186656&originHeight=582&originWidth=1216&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=159905&status=done&style=none&taskId=u8f2f14bc-99d9-409b-8806-ae2d68491ed&title=&width=972.8)<br />使用数学表达式如下：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683206549138-abf06d96-f642-4d7a-99ee-32411f652268.png#averageHue=%23faf2f2&clientId=u84dae985-42ee-4&from=paste&height=300&id=uf1c1cfe6&originHeight=375&originWidth=1172&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=95413&status=done&style=none&taskId=u7b918ca6-d3aa-4ea3-bc97-a49f262b690&title=&width=937.6)<br />对E(u,v)表达式进行泰勒展开：<br />$I(x+u, y+v) \approx I(x, y)+u I_{x}+v I_{y}$<br />$\begin{aligned}
E(u, v) & =\sum_{(x, y)} w(x, y) \times\left[I(x, y)+u I_{x}+v I_{y}-I(x, y)\right]^{2} \\
& =\sum_{(x, y)} w(x, y) \times\left(u I_{x}+v I_{y}\right)^{2} \\
& =\sum_{(x, y)} w(x, y) \times\left(u^{2} I_{x}^{2}+v^{2} I_{y}^{2}+2 u v I_{x} I_{y}\right)
\end{aligned}$<br />其中：<br />其中 Ix和Iy 是 I的偏微分，在图像中就是在 x 和 y 方向的梯度图（可以通过cv2.Sobel()来得到）：<br />$I_x=\frac{\partial I(x, y)}{\partial x}, \quad I_y=\frac{\partial I(x, y)}{\partial y}$<br />把 u 和 v 拿出来，得到最终的形式：<br />$E(u, v) \approx[u, v] M\left[\begin{array}{l} u \\ v \end{array}\right]$<br />其中矩阵M为：<br />$M=\sum_{(x, y)} w(x, y)\left[\begin{array}{cc} I_x^2 & I_x I_y \\ I_x I_y & I_y^2 \end{array}\right] \rightarrow R^{-1}\left[\begin{array}{cc} \lambda_1 & 0 \\ 0 & \lambda_2 \end{array}\right] R$<br />最后是把实对称矩阵对角化处理后的结果，可以把R看成旋转因子，其不影响两个正交方向的变化分量。经对角化处理后，将两个正交方向的变化分量提取出来，就是 λ1 和 λ2（特征值）。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683206914996-20392abf-5137-4e63-a30d-30abe7d9f2c0.png#averageHue=%23f0edec&clientId=u84dae985-42ee-4&from=paste&height=512&id=u5c31cde0&originHeight=640&originWidth=852&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=213982&status=done&style=none&taskId=uce42d619-4b40-4c52-b580-6358454d1a3&title=&width=681.6)<br />**平坦区域**：两个特征值都小，且近似相等，能量函数在各个方向上都较小；<br />**边缘区域**：一个特征值大，另一个特征值小，能量函数在某一方向上增大，其他方向较小；<br />**角点区域**：两个特征值都大，且近似相等，能量函数在所有方向上都增大。

为了不用单独求特征值，检测出特征向量很大的角点，使用如下角点响应函数来取值。计算每个窗口对应的得分（角点响应函数R）：<br />$R=\operatorname{det}(M)-k(\operatorname{trace}(\mathrm{M}))^2$<br />k 是一个经验常数，在范围 (0.04, 0.06) 之间。<br />但还有最后一步，根据 R 的值，将这个窗口所在的区域划分为平面、边缘或角点。为了得到最优的角点，我们还可以使用**非极大值抑制**。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683207578246-fde8d07c-f7ba-420c-b1d9-d5d0d75df5c9.png#averageHue=%23e09675&clientId=u84dae985-42ee-4&from=paste&height=389&id=u829ce8e4&originHeight=486&originWidth=814&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=188825&status=done&style=none&taskId=u36879cf9-3fd1-4d88-8f80-dc1db61f137&title=&width=651.2)<br />注意：Harris 检测器具有旋转不变性，但不具有尺度不变性，也就是说尺度变化可能会导致角点变为边缘，如下图所示：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683207153232-4f3d5850-7bba-4d1d-a4c0-5a23302a0495.png#averageHue=%23fdfdfd&clientId=u84dae985-42ee-4&from=paste&height=176&id=u147c57f6&originHeight=220&originWidth=534&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=35465&status=done&style=none&taskId=u1d56e11a-4ff8-4c1a-bddb-d617611258c&title=&width=427.2)<br /> 
<a name="woTKw"></a>
### 5.4.2 Shi-Tomasi角点
Shi-Tomasi角点，就是常说得GFTT（Good Features to Track）角点，它是 Harris 角点检测的改进版，Shi-Tomasi 方法在很多情况下可以得到比 Harris 算法更好的结果。<br />Harris 角点检测中每个窗口的分数公式是将矩阵 M 的行列式与 M 的迹相减：<br />$R=\lambda_1 \lambda_2-k\left(\lambda_1+\lambda_2\right)^2$<br />由于 Harris 角点检测算法的稳定性和 k 值有关，而 k 是个经验值，不好设定最佳值。Shi-Tomasi 发现，角点的稳定性其实和矩阵 M 的较小特征值有关，于是直接用较小的那个特征值作为分数。这样就不用调整k值了。所以 Shi-Tomasi 将分数公式改为如下形式：<br />$R=\min \left(\lambda_1, \lambda_2\right)$<br />和 Harris 一样，如果该分数大于设定的阈值，我们就认为它是一个角点。<br />我们可以把它绘制到 λ1 ～ λ2 空间中，就会得到下图：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683207853108-5ef5a8f1-29fa-40f3-9400-88919c6fed92.png#averageHue=%23b4e483&clientId=u84dae985-42ee-4&from=paste&height=286&id=u5ef3d579&originHeight=357&originWidth=528&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=52055&status=done&style=none&taskId=u7a023c6a-96d8-48bb-8840-72992b677a8&title=&width=422.4)
<a name="V831s"></a>
### 5.4.3 Fast
上述Harris角点与Shi-Tomasi角点都是基于梯度计算的角点检测方法，其计算复杂度高，图像中的噪声可以阻碍梯度计算。想要提高检测速度的话，可以考虑基于模板的方法：FAST角点检测算法。该算法原理比较简单，但实时性很强。<br />（Features from Accelerated Segment Test）由Edward Rosten和Tom Drummond在2006年首先提出，是近年来倍受关注的基于模板和机器学习的角点检测方法，它不仅计算速度快，还具有较高的精确度。Fast算法的基本原理就是使用周长为16个像素点（半径为3的Bresenham圆）来判定其圆心像素是否为角点。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683209864888-7156b994-494e-473a-a0d1-6a0b9e93e52d.png#averageHue=%23a4a4a4&clientId=u84dae985-42ee-4&from=paste&height=304&id=u5b3d466a&originHeight=380&originWidth=750&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=132628&status=done&style=none&taskId=ue48e0d7d-5759-4880-a338-dbdcef7b068&title=&width=600)<br />在圆周上按顺时针方向从1到16的顺序对圆周像素点进行编号。设圆心像素p的亮度值为Ip，阈值为t。如果在圆周上有连续N个像素的亮度值比Ip+t大，或者比Ip-t小，则圆心像素被称为角点。<br />$\left\{\begin{array}{lll} \text { 条件 } 1: \text { 连续 } N \text { 个像素 } x \text { 的像素亮度值 } I_x: & I_x>\left(I_p+t\right), & \text { if } I_x>I_p \\ \text { 条件 } 2: \text { 连续 } N \text { 个像素 } x \text { 的像素亮度值 } I_x: & I_x<\left(I_p-t\right), & \text { if } I_x<I_p \end{array}\right.$<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683210143552-8bfecd82-3b6d-4f1f-9917-75de1e96ba88.png#averageHue=%23e9e9e9&clientId=u84dae985-42ee-4&from=paste&height=62&id=u2b5530c0&originHeight=78&originWidth=732&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=16684&status=done&style=none&taskId=u6dcc3fe9-e354-496a-b701-dab9b88fd1a&title=&width=585.6)<br />Fast算法流程<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683210169560-cc7390b6-a7e4-4199-bb99-1b9b82830c0a.png#averageHue=%23ededed&clientId=u84dae985-42ee-4&from=paste&height=247&id=u7eb0ffba&originHeight=309&originWidth=800&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=55515&status=done&style=none&taskId=ub7a14b22-34ab-4721-a291-e221bc90d35&title=&width=640)<br />FAST非极大值抑制<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1782698/1683210223077-b41ccd86-05af-4c0d-8249-c3ba13030237.png#averageHue=%23efefef&clientId=u84dae985-42ee-4&from=paste&height=263&id=u2d8118cd&originHeight=329&originWidth=800&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=47486&status=done&style=none&taskId=u64e0c6c1-9376-4763-b44b-c087b684a53&title=&width=640)
<a name="qaIbG"></a>
## 本章小结
本章介绍了常见视觉特征点，有运算复杂度比较高的SIFT，SURF，也有基于模板，实时性好的Shi-Tomasi，ORB特征点。特征点的追踪是前端VO的基础，也是整个前端最耗时的部分之一。
<a name="GHyCc"></a>
## 本章思考
1.请说说SIFT或SURF的原理，并对比它们与ORB之间的优劣。<br />2.我们发现，OpenCV提供的ORB特征点在图像中分布不够均匀。你是否能够找到或提出让特征点分布更均匀的方法？
<a name="fnMow"></a>
## 附录
本章提到的大多数特征点，在opencv中都能找到对应接口，感兴趣的可以去看opencv的modules->features2d中对应实现，另外，在github上也有很多开源实现，在此列举几个：<br />sift的C++实现：[https://github.com/phoenix16/SIFT](https://github.com/phoenix16/SIFT)<br />surf的C++实现：[https://github.com/JairFrancesco/OpenSurf](https://github.com/JairFrancesco/OpenSurf)<br />KAZE：[https://github.com/pablofdezalc/kaze](https://github.com/pablofdezalc/kaze)<br />如果你想动手实践一下，可以用这个资料：[https://github.com/whoisraibolt/Feature-Detection-and-Description](https://github.com/whoisraibolt/Feature-Detection-and-Description)
<a name="FAzqK"></a>
## 参考
[1.SIFT特征点提取](https://blog.csdn.net/lingyunxianhe/article/details/79063547)<br />[2.SIFT算法](https://zhuanlan.zhihu.com/p/343522892)<br />[3.Surf算法特征点检测与匹配](https://blog.csdn.net/dcrmg/article/details/52601010)<br />[4.SURF特征提取算法](https://zhuanlan.zhihu.com/p/311415924)<br />[5.[基础知识] Speeded Up Robust Features （SURF特征）](https://zhuanlan.zhihu.com/p/365403867)<br />[6.图像处理基础（六）基于 LOG 的 blob 兴趣点检测](https://zhuanlan.zhihu.com/p/448959603)<br />[7.图像处理基础 （四）边缘提取之 LOG 和 DOG 算子](https://zhuanlan.zhihu.com/p/446286009)<br />[8.角点检测：Harris 与 Shi-Tomasi](https://zhuanlan.zhihu.com/p/83064609)<br />[9.【理解】经典角点检测算法--Harris角点](https://blog.csdn.net/SESESssss/article/details/106774854)<br />[10.FAST角点学习笔记](https://zhuanlan.zhihu.com/p/76501359)<br />[11.FAST角点检测学习笔记](https://zhuanlan.zhihu.com/p/489625338)<br />[12.（四十二）特征点检测-ORB](https://zhuanlan.zhihu.com/p/91479558)<br />[13.ORB特征提取详解](https://blog.csdn.net/zouzoupaopao229/article/details/52625678)<br />[14.图像特征算法(三)——ORB算法简述及Python中ORB特征匹配实践](https://zhuanlan.zhihu.com/p/261966288)<br />[15.ORB特征点检测](https://www.cnblogs.com/ronny/p/4083537.html)
